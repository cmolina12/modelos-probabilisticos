{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "87bd3d4d",
   "metadata": {},
   "source": [
    "# Complementaria Repaso Quiz 3 - Jueves 12:30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "678e51b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from jmarkov.mdp.dtmdp import dtmdp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "150426d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Matrices de transición (orden de estados: B, M, A)\n",
    "\n",
    "P_P = np.array([\n",
    "    [0.80, 0.18, 0.02],\n",
    "    [0.30, 0.55, 0.15],\n",
    "    [0.10, 0.50, 0.40]\n",
    "])\n",
    "\n",
    "P_G = np.array([\n",
    "    [0.55, 0.35, 0.10],\n",
    "    [0.15, 0.55, 0.30],\n",
    "    [0.05, 0.30, 0.65]\n",
    "])\n",
    "\n",
    "P_L = np.array([\n",
    "    [0.70, 0.25, 0.05],\n",
    "    [0.25, 0.55, 0.20],\n",
    "    [0.10, 0.45, 0.45]\n",
    "])\n",
    "\n",
    "P_S = np.array([\n",
    "    [0.90, 0.10, 0.00],\n",
    "    [0.50, 0.45, 0.05],\n",
    "    [0.25, 0.55, 0.20]\n",
    "])\n",
    "\n",
    "# Retornos inmediatos R(s,a) en miles de dólares\n",
    "retornos = np.array([#P   #G  #L  #S\n",
    "                    [60, 110, 70, 10],   # B\n",
    "                    [40,  80, 60,  5],   # M\n",
    "                    [20,  40, 35,  0]    # A\n",
    "                    ], dtype=float)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bff764a",
   "metadata": {},
   "source": [
    "## Parte A: Implementación del MDP"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "527a9e86",
   "metadata": {},
   "source": [
    "### 1. Espacio de estados, acciones, matrices de transición, matriz de retornos y objeto MDP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cd68bd5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "value_functions: [1532.63862521 1467.05680641 1410.94649533]\n",
      "optimal_policy: {np.str_('Baja'): np.str_('Operar en grande'), np.str_('Media'): np.str_('Operar en grande'), np.str_('Alta'): np.str_('Diversificar / Lavar')}\n"
     ]
    }
   ],
   "source": [
    "# Espacio de estados\n",
    "s_x = np.array([\"Baja\", \"Media\", \"Alta\"])\n",
    "\n",
    "# Espacio de acciones\n",
    "a_i = np.array([\"Operar en pequeño\", \"Operar en grande\", \"Diversificar / Lavar\", \"Pausar operaciones\"])\n",
    "    \n",
    "matrices = {}\n",
    "matrices[\"Operar en pequeño\"] = P_P\n",
    "matrices[\"Operar en grande\"] = P_G\n",
    "matrices[\"Diversificar / Lavar\"] = P_L\n",
    "matrices[\"Pausar operaciones\"] = P_S\n",
    "\n",
    "# Matriz de retornos\n",
    "retornos = np.array([  # P    G    L    S\n",
    "                    [60, 110, 70, 10],   # B\n",
    "                    [40,  80, 60,  5],   # M\n",
    "                    [20,  40, 35,  0]    # A\n",
    "                    ], dtype=float)\n",
    "\n",
    "# Crear el objeto MDP\n",
    "mdp = dtmdp(s_x, a_i, matrices, retornos, discount_factor=0.95)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3824de52",
   "metadata": {},
   "source": [
    "### 2. Valores óptimos para cada estado usando iteración de política"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "6c659be4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "value_functions: [1532.65965066 1467.07725411 1410.96627588]\n"
     ]
    }
   ],
   "source": [
    "value_functions, optimal_policy = mdp.solve(tolerance=0, minimize=False, method=\"policy_iteration\")\n",
    "\n",
    "print(f\"value_functions: {value_functions}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1282720",
   "metadata": {},
   "source": [
    "### 3. Obtenga la política óptima"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "e23ea246",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "optimal_policy: {np.str_('Baja'): np.str_('Operar en grande'), np.str_('Media'): np.str_('Operar en grande'), np.str_('Alta'): np.str_('Diversificar / Lavar')}\n"
     ]
    }
   ],
   "source": [
    "print(f\"optimal_policy: {optimal_policy}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc752982",
   "metadata": {},
   "source": [
    "### 4. Calcule el valor esperado de la política óptima en el largo plazo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "b4adaef5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.float64(1464.999999864065)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mdp.expected_policy_value(value_functions, optimal_policy)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cf25bbb",
   "metadata": {},
   "source": [
    "### 5. Genere la matriz de transición inducida por la política óptima"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "cc9388e1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.55</td>\n",
       "      <td>0.35</td>\n",
       "      <td>0.10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.15</td>\n",
       "      <td>0.55</td>\n",
       "      <td>0.30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.10</td>\n",
       "      <td>0.45</td>\n",
       "      <td>0.45</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      0     1     2\n",
       "0  0.55  0.35  0.10\n",
       "1  0.15  0.55  0.30\n",
       "2  0.10  0.45  0.45"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mdp.policy_transition_matrix(optimal_policy)\n",
    "\n",
    "pd.DataFrame(mdp.policy_transition_matrix(optimal_policy))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "165be125",
   "metadata": {},
   "source": [
    "## Parte B: Simulación de Monte Carlo\n",
    "Realice una smulación de Monte Carlo con 1000 escenarios, cada uno con 25 semanas, inciiando en el estado Media (M) y aplicando la política óptima $\\pi^*$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61c241a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuración de la simulación\n",
    "numero_escenarios = 10000  # Aumentamos para mayor precisión\n",
    "semanas_a_estudiar = 8\n",
    "estado_inicial = \"Media\"\n",
    "\n",
    "# Mapeo de estados a índices\n",
    "estado_a_indice = {estado: idx for idx, estado in enumerate(s_x)}\n",
    "\n",
    "# Contador de escenarios con al menos una presión Alta\n",
    "contador_alta = 0\n",
    "\n",
    "# Semilla para reproducibilidad\n",
    "np.random.seed(0)\n",
    "\n",
    "# Simulación de Monte Carlo\n",
    "for _ in range(numero_escenarios):\n",
    "    estado_actual = estado_inicial\n",
    "    presion_alta = False\n",
    "    \n",
    "    for semana in range(semanas_a_estudiar):\n",
    "        # Obtener la acción según la política óptima\n",
    "        accion = optimal_policy[estado_actual]\n",
    "        \n",
    "        # Obtener índice del estado actual\n",
    "        estado_idx = estado_a_indice[estado_actual]\n",
    "        \n",
    "        # Transición al siguiente estado\n",
    "        dist_prob = matrices[accion][estado_idx]\n",
    "        estado_actual = np.random.choice(s_x, p=dist_prob)\n",
    "        \n",
    "        # Verificar si alcanzó presión Alta\n",
    "        if estado_actual == \"Alta\":\n",
    "            presion_alta = True\n",
    "            \n",
    "    # Incrementar contador si hubo al menos una presión Alta\n",
    "    if presion_alta:\n",
    "        contador_alta += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84e28e53",
   "metadata": {},
   "source": [
    "### 1. ¿Cual es el ingreso acumulado espeardo (en miles de dólares) durante las 25 semanas?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "f6901cdc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "El ingreso acumulado esperado en 25 semanas es: $1,844.18 (en miles de dólares)\n"
     ]
    }
   ],
   "source": [
    "# Cálculo del ingreso acumulado esperado\n",
    "ingreso_acumulado_esperado = np.mean(np.sum(ingresos, axis=0))\n",
    "\n",
    "print(f\"El ingreso acumulado esperado en {numero_semanas} semanas es: ${ingreso_acumulado_esperado:,.2f} (en miles de dólares)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2db3af75",
   "metadata": {},
   "source": [
    "### 2. ¿Cuál es la probabilidad estimada de que Walter sienta una presión Alta al menos una vez en las primeras 8 semanas?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "79141668",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Probabilidad de presión Alta en las primeras 8 semanas: 88.14%\n"
     ]
    }
   ],
   "source": [
    "# Calcular probabilidad\n",
    "probabilidad_alta = (contador_alta / numero_escenarios) * 100\n",
    "\n",
    "print(f\"Probabilidad de presión Alta en las primeras {semanas_a_estudiar} semanas: {probabilidad_alta:.2f}%\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
